{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Conv2D, GlobalMaxPool2D\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_row(line, rest=True):\n",
    "    '''\n",
    "    Filter logs for lines with\n",
    "    greater variation.\n",
    "    '''\n",
    "    if rest:\n",
    "        return line.startswith('GET') or line.startswith('POST') or line.startswith('modo=') or line.startswith('id=')\n",
    "    else:\n",
    "        return line.startswith('GET') or line.startswith('POST')\n",
    "\n",
    "def read_format(file_name):\n",
    "    '''\n",
    "    Filter out http://localhost:8080... not informative\n",
    "    '''\n",
    "    with open(file_name, 'r') as infile:\n",
    "        data = infile.readlines()\n",
    "    data = [line.strip() for line in data]\n",
    "    data = [line for line in data if target_row(line)]\n",
    "    r_data = []\n",
    "    start_string = data[0].lower()\n",
    "    for line in data[1:]:\n",
    "        if target_row(line, rest=False):\n",
    "            r_data.append(start_string)\n",
    "            start_string = line.replace('http://localhost:8080', '').lower()\n",
    "        else:\n",
    "            start_string += ' ' + line.replace('http://localhost:8080', '').lower()\n",
    "    return r_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = read_format('normalTrafficTest.txt')\n",
    "anom_data = read_format('anomalousTrafficTest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['get http://localhost:8080/tienda1/publico/anadir.jsp?id=2&nombre=jam%f3n+ib%e9rico&precio=85&cantidad=%27%3b+drop+table+usuarios%3b+select+*+from+datos+where+nombre+like+%27%25&b1=a%f1adir+al+carrito http/1.1',\n",
       " 'post /tienda1/publico/anadir.jsp http/1.1 id=2&nombre=jam%f3n+ib%e9rico&precio=85&cantidad=%27%3b+drop+table+usuarios%3b+select+*+from+datos+where+nombre+like+%27%25&b1=a%f1adir+al+carrito',\n",
       " 'get /tienda1/publico/anadir.jsp?id=2%2f&nombre=jam%f3n+ib%e9rico&precio=85&cantidad=49&b1=a%f1adir+al+carrito http/1.1',\n",
       " 'post /tienda1/publico/anadir.jsp http/1.1 id=2%2f&nombre=jam%f3n+ib%e9rico&precio=85&cantidad=49&b1=a%f1adir+al+carrito',\n",
       " 'get /asf-logo-wide.gif~ http/1.1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anom_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# perhaps byte-pair encodings would be most efficient  https://github.com/rsennrich/subword-nmt\n",
    "# filtering out the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dict = {}\n",
    "char_smpl = ' '.join(anom_data)\n",
    "char_smpl = sorted(list(set(char_smpl)))\n",
    "for idx, ch in enumerate(char_smpl):\n",
    "    char_dict[ch] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anom_data = [[char_dict[el] for el in line] for line in anom_data]\n",
    "norm_data = [[char_dict[el] for el in line] for line in norm_data]\n",
    "data = anom_data + norm_data\n",
    "target = np.ones(len(anom_data)).tolist() + np.zeros(len(norm_data)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = np.max([len(line) for line in data])\n",
    "n_inputs = len(char_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for line in data:\n",
    "    ret_mat = np.zeros((n_steps, n_inputs))\n",
    "    for idx, val in enumerate(line):\n",
    "        ret_mat[idx] = np.eye(n_inputs)[val]\n",
    "    train.append(ret_mat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.asarray(train)\n",
    "target = np.asarray(target)\n",
    "train = np.expand_dims(train, axis=-1)\n",
    "rnd_idx = list(range(train.shape[0]))\n",
    "np.random.shuffle(rnd_idx)\n",
    "N = 1000\n",
    "train, target, test, tst_target = train[rnd_idx][:-N], target[rnd_idx][:-N], train[rnd_idx][-N:], target[rnd_idx][-N:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_network():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, n_inputs), input_shape=(n_steps, n_inputs, 1)))\n",
    "    \n",
    "    model.add(GlobalMaxPool2D())\n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.3))\n",
    "    \n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.3))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/funk/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/funk/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "NN = build_network()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.03, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 875, 1, 32)        7872      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 9,745\n",
      "Trainable params: 9,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53699 samples, validate on 5967 samples\n",
      "Epoch 1/20\n",
      "53699/53699 [==============================] - 107s - loss: 0.2216 - acc: 0.8950 - val_loss: 0.1058 - val_acc: 0.9437\n",
      "Epoch 2/20\n",
      "53699/53699 [==============================] - 81s - loss: 0.1123 - acc: 0.9449 - val_loss: 0.0980 - val_acc: 0.9506\n",
      "Epoch 3/20\n",
      "53699/53699 [==============================] - 81s - loss: 0.0974 - acc: 0.9506 - val_loss: 0.0896 - val_acc: 0.9502\n",
      "Epoch 4/20\n",
      "53699/53699 [==============================] - 80s - loss: 0.0879 - acc: 0.9541 - val_loss: 0.0784 - val_acc: 0.9551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd8f51e5eb8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.fit(x=train, y=target, epochs=20, validation_split=0.1, batch_size=32, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 960/1000 [===========================>..] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.062154329518321901, 0.96499999999999997]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.evaluate(test, tst_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
